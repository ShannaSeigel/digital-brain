---
# layout: note
title: The Reasonable Robot - AI and the Law
author: Shanna
---

# Webinar on The Reasonable Robot: AI and the Law

Author Ryan Abbott, professor of law and health sciences, speaking about his recent book *["The Reasonable Robot: Artificial Intelligence and the Law"](https://thereasonablerobot.com/)* Webinar hosted by the Center for Data Innovation, moderated by Daniel Castro, organization director. November 13, 2020.
- [Goodreads link](https://www.goodreads.com/book/show/48989663-the-reasonable-robot?from_search=true&from_srp=true&qid=XJ4YR2pj4U&rank=1)
- [Webinar link](https://www.youtube.com/watch?v=s8VglfNKjLs)
- [Past lectures from Center for Data Innovation](https://www.eventbrite.com/o/center-for-data-innovation-5577375235)

## Overview
***The main argument by Abbott is that laws should hold humans and artificial intelligences to the same legal standards. Currently people and machines are not facing the same sets of laws when performing the same activities or outputs.***

> [the law does not] differentiate between behavior done by a machine and behavior done by a person. ‚Äì Ryan Abbott

> If we have law that becomes agnostic to humans or machines, we may have better social outcomes. ‚Äì Ryan Abbott

Currently machines are able to step into roles traditionally held by people. Automation is used in many fields and uptake of automation and artificial intelligence will only increase in the future. Abbott argues that when the law makes a distinction between human behavior and AI behavior there can be negative outcomes. According to Castro, the book gives many concrete examples regarding outcomes with or without changes to current US laws.

Abbott's goal would be "legal neutrality" between AI and humans and would like to create more opportunities for transparency, fairness, and accountability when it comes to how AI is regulated. Examples include tax law and patent law.

A distinction is made between humans inherently having moral rights and an AI having the same or any rights. An AI may not have certain rights universally but there may be instances where a right should be given to an AI. US law already grants some rights to artificial persons in the form of corporations in hopes that those granted rights will result in good social outcomes.
- Though this is a reminder of times when companies have used their rights as a person to create, in my opinion, poor social outcomes. Like companies that can refuse to cover birth control as part of their employee health plan since it violates the religious beliefs of the company. 
	- Am I understanding the Hobby Lobby case correctly? That it's the company, not the owners, that can refuse this on religious grounds ‚ùì 

## Tax Law & AI

How we tax automation can have implications for the future of work. There have been many examples in the past of machine innovation or automation threatening human workers. Over time, those industries became more productive and people moved into different job roles. There is individual harm in these transition periods when a person fears for their job and/or is put out work. When people are "rendered technologically unemployed."
- I've seen discussion about the times in history with big machine shifts. Was it a Vox video? It was this same idea about waves of new technology and the shift of workers into different jobs, related or otherwise. AI and other tech may cause the same displacement seen in the past and governments would be wise to invest in training workers for new roles to avoid spikes in unemployment.
	- Found it: [The big debate about the future of work](https://www.youtube.com/watch?v=TUmyygCMMGA) (Vox 2017)
		- "Jobs have gone away but "work" persists"
		- #sgs-to-review - add more content on subject?

Businesses are taxed differently based on whether a job is done by a human or done by a machine. 

> Even if a person and a machine are doing the same job, we tax them differently, and this drives businesses to automate. - Ryan Abbott

### Example: Touch Screen Food Ordering

If a machine is able to take an order instead of a cashier or a server then the business does not have to pay payroll tax. **This saves the business money and incentivises them to automate job roles over hiring a person.**

Robots don't pay taxes. A majority of US tax revenue comes from payroll and income tax. According to Abbott, less than 10% of US tax revenue comes from corporate taxes. Replacing humans with machines can decrease US tax revenue through the loss of income and payroll taxes. The business may become more profitable but that money will be tightly controlled by the business owners and may not flow back into the economy (and certainly not to state or federal government). This also displaces a lot of workers.
- Aside: Seriously?? I guess I always knew some businesses used tax loopholes like crazy but I didn't know the number was that low. This raises so many questions for me. Why are we as a country placing the burden of tax revenue on the average worker? How is the average American worker paying more in taxes than the huge company they may work for? How have I never questioned income tax before now?
	- Turns out Abbott has two possible answers to this:
		- Labor done within the country is easy to tax. Profit from a business may come from international revenue sources and may be reinvested into parts of the business outside of the country. Taxing labor within our borders ensures money will be collected.
			- Still seems shitty
		- There are concerns that increased corporate tax will discourage investment into American businesses, which could in turn hurt the economy at large. Abbott says there are numerous reviews of this idea that show this doesn't happen in reality. Even when compared to places with less/no corporate taxes, people invest in US businesses over businesses based in those other countries. 
			- So, practically, this is also a bullshit reason.

Aside from lost tax revenue through automation over humans, there is also less money for social programs, like those that may retrain workers that have been displaced by automation.

## Tax the Bots

One solution is to have neutral tax law between humans and machines, including having robots pay taxes. There are problems with this approach though:
- How do we define a robot for tax purposes? Or in general?
- A robot might not replace a human worker on a one-to-one basis. The human employee may be able to do a task differently or may cover many tasks while a machine may only do one.
- This will create more admin work
- A lot of people will try to avoid paying taxes on robots

**An alternative option is to decrease or remove tax on labor in the US.** This "removes the burden on something socially valuable: labor." When businesses consider automation it can be for non-tax reasons.

Note that this still lowers revenue generated by income tax, which means the country will still have to examine how we tax labor vs profit and workers vs businesses.

## Tort Law: Laws About Accidents

I've heard of tort laws but know nothing about them. Could look up some more information. #sgs-read-more-on-subject 

### Example: Autonomous Vehicles

An AI could be as good as a human driver and in the future could be better than a human driver. When we look at laws governing humans and driverless cars we're dealing with two sets of laws.
- An Uber driver that gets into an accident can be judged by negligence laws.
- A driverless car is a company product, which is held to product liability laws. These are more strict than negligence laws.
	- This makes sense since we want safe products and we want companies to be held responsible when selling unsafe products.

Does it make sense to have a higher level of liability for the driverless car when it could be safer than the human alternative? Humans are not the safest drivers. Driverless cars won't be free of accidents but it's possible that they will safer than a human driver and use could result in fewer accidents overall. 

Abbott says we should be comparing AI drivers to human drivers. He also argues that more strict laws on driverless cars can discourage the uptake of automation and ultimately innovation. For humans we generally don't ask why a driver ran a red light, we just have a consequence for the action. The time and money needed to find out *why* an autonomous vehicle ran a red light would be more costly than just asking "did the car run a red light?" This lets the law hold the car responsible for the mistake even if it doesn't ask why the mistake happened.

Abbott suggests we hold people to the standard of a reasonable AI instead of holding each to different laws. One could argue that a driverless car is a safer alternative to a human driver. If you choose to drive without AI you will still be responsible for the mistakes you make as a driver.
- Author points out that you could take the argument further and say why even let humans drive if AI is safer? But this restricts human autonomy.
	- Also this idea makes me uncomfortable because it seems like it would lead to over-reliance on technology that can fail or be hacked. What happens if you can't easily repair a driverless car in an emergency?
	- I remember reading an article about a driverless car being hacked and made to drive around differently than intended. I can't remember the source. Find ‚ùì 


## AI in Human Professions
Can AI impact how people practice their profession, like medicine or law? Surgical robots (da Vinci pictured in talk) are sophisticated tools used by humans. Could there be robots in the future that can perform surgery themselves? What if they can do a procedure more safely than a human surgeon, would it be ethical to allow a human to perform surgery when a safer option is available?
- This brings up practical questions for me. Physicians would still need to know how to do a surgery to oversee the robot. Plus there may be areas with less access to new technology and they'll still need human surgeons. Again, what if the AI fails or is altered in a dangerous way? A physician would need to take over in an emergency.


## Can Machines Become Creative Workers?
The Washington Post now uses a machine for short stories and people can't tell the difference between AI written articles or articles written by human journalists. We've gone from pretty terrible stories, pictures, etc. made by AI to creative outputs that aren't too bad. Some can be really useful, like generating news quickly, or even put out music or images that resonate with people. These creative works are also fast and cheap to make. So these artificially created works can have commercial value.

## Laws Regarding Creative Works
Works made by machines and humans fall under different laws. Copyright law generally requires a human. If a machine creates an image, can you copyright it as the creator of the machine? Does the image become open for public use since there is no human creator? Would articles generated for the Washington Post be owned by the paper or could other papers reprint the article without it being plagiarism? Is the AI credited as the author? Who or what receives the credit?

### Example: Corporate Work for Hire Doctrine
In the US you can be hired by a company to create content for them. If you write an article for Google, they own that content, not you. In practice, the US copyright office does not extend this to AI generated work.

### Copyright for AI Created Work
Precedent was set by ["Burrow-Giles Lithographic Company v. Sarony"](https://supreme.justia.com/cases/federal/us/111/53/) in 1884, which extended copyright protection to photography ([Wiki summary](https://www.wikiwand.com/en/Burrow-Giles_Lithographic_Co._v._Sarony)). The argument from SCOTUS was that expression of the artist and ideas from their mind, even a photograph, are owned by the creator.

The present day implication is that the US copyright office says AI do not have minds and cannot think, therefore they can not claim copyright on works they create.


## AI Patents
Abbott is leading two test cases regarding patents and AI created inventions. He gave two examples where AI were trained to create ideas about a product and eventually generated a new invention related to the product. In both cases the engineers were surprised by the idea created by the AI. But the AI cannot be credited as the inventor according to the US patent office. One purpose for listing the inventor as an AI and pushing the case for the patent office to accept this is to notify the public of the inventor and to not falsely credit a human (false representation as the inventor for a patent is a crime). The cases argue that the owner of the AI would own the invention patent but the inventor is properly credited as the AI.

### Example: Car Parts
A business used AI to generate ideas related to car parts. A new car part suggested by the AI looked promising and the company wanted to patent it. None of the engineers involved in creating and training the AI would put their name down as the inventor since the AI did all of the inventive work.

Some arguments have been made that a machine doesn't care about copyright or patent protections so there is no reason to create patents for their output. The people making the machines for the purpose of getting a creation DO care about securing patents and right now that requires a human inventor. 

Abbott says allowing AI to be credited as the inventor of a new item will encourage innovation instead of discouraging the use of AI in development endeavors

There could be a point in the future where turning to AI for assistance with creation will be normal. The example was given of a pharmaceutical company turning to another company with an AI that has been training on a huge antibody library. The AI could be shown what we know about covid-19 and asked to provide antibody treatment options. Great, but the pharm company can't patent the treatment so that will discourage them from using an available resource. 

Another future issue around patents has to do with how they are judged currently. An innovation is judged by whether the average inventor could have come up with the same thing or if it's truly novel. What happens if the "average inventor" uses AI as a tool all the time? If you're in field A and the AI gives you access to information on fields B-D, is your invention something that can be reasonably expected to be created by someone else in field A?


## Applications to Criminal Law
In law, we care about preventing/punishing anti-social behavior but we also care about *intent.* So if machines are acting like humans, could they behave in a way that constitutes a crime even if the AI doesn't have a "mental state" to examine for intent?

We already hold corporations accountable for committing crimes but the mental state of the company is attributed to people managing the company. Punishing the company can punish individual workers, so should the company be held responsible or the people abusing the power of their company? There are also arguments that a company *can* have a corporate atmosphere that goes beyond the people running the company, so you can punish a company for a crime. Group thinking and layers of behavior within a company can be hard to attribute to a single person for prosecution purposes.

So as machines get more autonomous and more complicated, how would you attribute AI behavior to a single human? Are we holding the AI creators liable for AI actions? Are there behaviors that we as a society can say we need to punish no matter the actor? 

Abbott notes that a lot of these ideas have not become wide-spread social issues but should be explored. 


------------------------


#### üóíRelated Notes



#### Tags
#robotics
#artificial-intelligence
#AI-laws
#live-lecture


<small>‚Ü≥ <i>Created 11-13-2020 / Updated ‚àû </i></small>




